{
  "hash": "7dd708510ddfba9d2b7938c6438cda1c",
  "result": {
    "markdown": "---\ntitle: \"Pumpkin Market\"\nauthor: \n  - name: Kate Becker\n    url: https://kateebeckerr.github.io/\n    affiliation: Master of Environmental Data Science Program at The Bren School (UCSB)\n    affiliation-url: https://ucsb-meds.github.io/ \ndate: \"2024-09-03\"\ncategories: [MEDS, MACHINE LEARNING, DEPARTMENT OF AGRICULTURE, DATA ACCESS, R]\nimage: pumpkins.jpeg\ndraft: false \noutput:\n  pdf_document: default\n  html_document: default\n---\n\n\n\n\n# Case Study: The Pumpkin Market\n\nThe data you just loaded includes 1757 lines of data about the market for pumpkins, sorted into groupings by city. This is raw data extracted from the Specialty Crops Terminal Markets Standard Reports distributed by the United States Department of Agriculture.\n\nYou are loading a pumpkin data set in order to ask questions of it:\n\nWhen is the best time to buy pumpkins?\n\nWhat price can I expect of a case of miniature pumpkins?\n\nShould I buy them in half-bushel baskets or by the 1 1/9 bushel box?\n\n## Examine the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#examine data\nglimpse(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 1,757\nColumns: 27\n$ ...1              <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ `City Name`       <chr> \"BALTIMORE\", \"BALTIMORE\", \"BALTIMORE\", \"BALTIMORE\", …\n$ Type              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Package           <chr> \"24 inch bins\", \"24 inch bins\", \"24 inch bins\", \"24 …\n$ Variety           <chr> NA, NA, \"HOWDEN TYPE\", \"HOWDEN TYPE\", \"HOWDEN TYPE\",…\n$ `Sub Variety`     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Grade             <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Date              <chr> \"4/29/17\", \"5/6/17\", \"9/24/16\", \"9/24/16\", \"11/5/16\"…\n$ `Low Price`       <dbl> 270, 270, 160, 160, 90, 90, 160, 160, 160, 160, 160,…\n$ `High Price`      <dbl> 280, 280, 160, 160, 100, 100, 170, 160, 170, 160, 17…\n$ `Mostly Low`      <dbl> 270, 270, 160, 160, 90, 90, 160, 160, 160, 160, 160,…\n$ `Mostly High`     <dbl> 280, 280, 160, 160, 100, 100, 170, 160, 170, 160, 17…\n$ Origin            <chr> \"MARYLAND\", \"MARYLAND\", \"DELAWARE\", \"VIRGINIA\", \"MAR…\n$ `Origin District` <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ `Item Size`       <chr> \"lge\", \"lge\", \"med\", \"med\", \"lge\", \"lge\", \"med\", \"lg…\n$ Color             <chr> NA, NA, \"ORANGE\", \"ORANGE\", \"ORANGE\", \"ORANGE\", \"ORA…\n$ Environment       <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ `Unit of Sale`    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Quality           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Condition         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Appearance        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Storage           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Crop              <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ Repack            <chr> \"E\", \"E\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N…\n$ `Trans Mode`      <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ...26             <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ ...27             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Clean names to the snake_case convention\n\npumpkins <- dat %>% clean_names(case = \"snake\")\n\n# Return column names\n\npumpkins %>% names()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"x1\"              \"city_name\"       \"type\"            \"package\"        \n [5] \"variety\"         \"sub_variety\"     \"grade\"           \"date\"           \n [9] \"low_price\"       \"high_price\"      \"mostly_low\"      \"mostly_high\"    \n[13] \"origin\"          \"origin_district\" \"item_size\"       \"color\"          \n[17] \"environment\"     \"unit_of_sale\"    \"quality\"         \"condition\"      \n[21] \"appearance\"      \"storage\"         \"crop\"            \"repack\"         \n[25] \"trans_mode\"      \"x26\"             \"x27\"            \n```\n:::\n:::\n\n\n## Select desired columns\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#df wrangling selecting for variety, city_name, package, low_price, high_price, and date variables\npumpkins <- pumpkins %>% select(variety, city_name, package, low_price, high_price, date)\n\n\n## Print data set\npumpkins %>% slice_head(n = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 6\n  variety     city_name package      low_price high_price date   \n  <chr>       <chr>     <chr>            <dbl>      <dbl> <chr>  \n1 <NA>        BALTIMORE 24 inch bins       270        280 4/29/17\n2 <NA>        BALTIMORE 24 inch bins       270        280 5/6/17 \n3 HOWDEN TYPE BALTIMORE 24 inch bins       160        160 9/24/16\n4 HOWDEN TYPE BALTIMORE 24 inch bins       160        160 9/24/16\n5 HOWDEN TYPE BALTIMORE 24 inch bins        90        100 11/5/16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## Load lubridate\n\nlibrary(lubridate)\n\n# Extract the month and day from the dates and add as new columns\npumpkins <- pumpkins %>%\n  mutate(date = mdy(date),  \n         day = yday(date),\n         month = month(date))\npumpkins %>% \n  select(-day)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1,757 × 7\n   variety     city_name package      low_price high_price date       month\n   <chr>       <chr>     <chr>            <dbl>      <dbl> <date>     <dbl>\n 1 <NA>        BALTIMORE 24 inch bins       270        280 2017-04-29     4\n 2 <NA>        BALTIMORE 24 inch bins       270        280 2017-05-06     5\n 3 HOWDEN TYPE BALTIMORE 24 inch bins       160        160 2016-09-24     9\n 4 HOWDEN TYPE BALTIMORE 24 inch bins       160        160 2016-09-24     9\n 5 HOWDEN TYPE BALTIMORE 24 inch bins        90        100 2016-11-05    11\n 6 HOWDEN TYPE BALTIMORE 24 inch bins        90        100 2016-11-12    11\n 7 HOWDEN TYPE BALTIMORE 36 inch bins       160        170 2016-09-24     9\n 8 HOWDEN TYPE BALTIMORE 36 inch bins       160        160 2016-09-24     9\n 9 HOWDEN TYPE BALTIMORE 36 inch bins       160        170 2016-10-01    10\n10 HOWDEN TYPE BALTIMORE 36 inch bins       160        160 2016-10-01    10\n# ℹ 1,747 more rows\n```\n:::\n\n```{.r .cell-code}\n## View the first 7 rows\n\npumpkins %>% slice_head(n = 7)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 8\n  variety     city_name package      low_price high_price date         day month\n  <chr>       <chr>     <chr>            <dbl>      <dbl> <date>     <dbl> <dbl>\n1 <NA>        BALTIMORE 24 inch bins       270        280 2017-04-29   119     4\n2 <NA>        BALTIMORE 24 inch bins       270        280 2017-05-06   126     5\n3 HOWDEN TYPE BALTIMORE 24 inch bins       160        160 2016-09-24   268     9\n4 HOWDEN TYPE BALTIMORE 24 inch bins       160        160 2016-09-24   268     9\n5 HOWDEN TYPE BALTIMORE 24 inch bins        90        100 2016-11-05   310    11\n6 HOWDEN TYPE BALTIMORE 24 inch bins        90        100 2016-11-12   317    11\n7 HOWDEN TYPE BALTIMORE 36 inch bins       160        170 2016-09-24   268     9\n```\n:::\n:::\n\n\nThere are two column dealing with price, high and low. Let's combine them into a single average price column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a new column price\npumpkins <- pumpkins %>% \n  mutate(price = (low_price+ high_price)/2)\n```\n:::\n\n\nLet's take a look at pumpkins sales throughout the year.\n\n*Question 1:* Create a scatter plot using price on the y-axis and day on the x-axis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make a scatter plot of month and price\n\nggplot(data = pumpkins, aes(x = day, y = price)) +\n  geom_point() +\n  ggtitle(\"Pumpkin Sales Throughout the Year\")\n```\n\n::: {.cell-output-display}\n![](Lab1-ML_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nNow, before we go any further, let's take another look at the data. Notice anything odd?\n\nFrom day 225 to 365 there appears to be a much larger range in pumpkin prices rather than any other time of year which can be explained by the holiday season and therefore there are more configurations of pumpkins that are sold at that time of year. For the rest of the year, the pumpkin price remains generally the same at around 225 to 275.\n\nThat's right: pumpkins are sold in many different configurations. Some are sold in 1 1/9 bushel measures, and some in 1/2 bushel measures, some per pumpkin, some per pound, and some in big boxes with varying widths.\n\nLet's verify this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Verify the distinct observations in Package column\npumpkins %>% \n  distinct(package)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 1\n   package             \n   <chr>               \n 1 24 inch bins        \n 2 36 inch bins        \n 3 50 lb sacks         \n 4 1 1/9 bushel cartons\n 5 1/2 bushel cartons  \n 6 1 1/9 bushel crates \n 7 bushel cartons      \n 8 bins                \n 9 35 lb cartons       \n10 each                \n11 20 lb cartons       \n12 50 lb cartons       \n13 40 lb cartons       \n14 bushel baskets      \n15 22 lb cartons       \n```\n:::\n:::\n\n\nPumpkins seem to be very hard to weigh consistently, so let's filter them by selecting only pumpkins with the string bushel in the package column and put this in a new data frame \"new_pumpkins\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## View the first few rows of the data\n\npumpkins %>% slice_head(n = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 9\n  variety    city_name package low_price high_price date         day month price\n  <chr>      <chr>     <chr>       <dbl>      <dbl> <date>     <dbl> <dbl> <dbl>\n1 <NA>       BALTIMORE 24 inc…       270        280 2017-04-29   119     4   275\n2 <NA>       BALTIMORE 24 inc…       270        280 2017-05-06   126     5   275\n3 HOWDEN TY… BALTIMORE 24 inc…       160        160 2016-09-24   268     9   160\n4 HOWDEN TY… BALTIMORE 24 inc…       160        160 2016-09-24   268     9   160\n5 HOWDEN TY… BALTIMORE 24 inc…        90        100 2016-11-05   310    11    95\n```\n:::\n\n```{.r .cell-code}\npumpkins %>% distinct(package)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 1\n   package             \n   <chr>               \n 1 24 inch bins        \n 2 36 inch bins        \n 3 50 lb sacks         \n 4 1 1/9 bushel cartons\n 5 1/2 bushel cartons  \n 6 1 1/9 bushel crates \n 7 bushel cartons      \n 8 bins                \n 9 35 lb cartons       \n10 each                \n11 20 lb cartons       \n12 50 lb cartons       \n13 40 lb cartons       \n14 bushel baskets      \n15 22 lb cartons       \n```\n:::\n:::\n\n\n*Question* 2: Use a combination of dplyr::filter() and stringr::str_detect() to achieve what we want.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Retain only pumpkins with \"bushel\" in the package column\n#bushel <- pumpkins %>%\n  #select(package = \"bushel\")\n\nnew_pumpkins <- pumpkins %>% \n    filter(str_detect(package, \"bushel\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the dimensions of the new data\ndim(new_pumpkins)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 415   9\n```\n:::\n\n```{.r .cell-code}\n# View a few rows of the new data\nnew_pumpkins %>% \n  slice_head(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 9\n   variety  city_name package  low_price high_price date         day month price\n   <chr>    <chr>     <chr>        <dbl>      <dbl> <date>     <dbl> <dbl> <dbl>\n 1 PIE TYPE BALTIMORE 1 1/9 b…        15       15   2016-09-24   268     9  15  \n 2 PIE TYPE BALTIMORE 1 1/9 b…        18       18   2016-09-24   268     9  18  \n 3 PIE TYPE BALTIMORE 1 1/9 b…        18       18   2016-10-01   275    10  18  \n 4 PIE TYPE BALTIMORE 1 1/9 b…        17       17   2016-10-01   275    10  17  \n 5 PIE TYPE BALTIMORE 1 1/9 b…        15       15   2016-10-08   282    10  15  \n 6 PIE TYPE BALTIMORE 1 1/9 b…        18       18   2016-10-08   282    10  18  \n 7 PIE TYPE BALTIMORE 1 1/9 b…        17       17   2016-10-08   282    10  17  \n 8 PIE TYPE BALTIMORE 1 1/9 b…        17       18.5 2016-10-08   282    10  17.8\n 9 PIE TYPE BALTIMORE 1 1/9 b…        15       15   2016-10-15   289    10  15  \n10 PIE TYPE BALTIMORE 1 1/9 b…        17       17   2016-10-15   289    10  17  \n```\n:::\n:::\n\n\nYou should see that we have narrowed down to 415 rows of data containing pumpkins measured in bushels.\n\nBut wait! There's one more thing to do.\n\nDid you notice that the bushel amount varies per row? You need to normalize the pricing so that you show the pricing per bushel, not per 1 1/9 or 1/2 bushel. Time to do some math to standardize it.\n\nWe'll use the function case_when() to mutate the Price column depending on some conditions. case_when() allows you to vectorize multiple if_else()statements.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Convert the price if the Package contains fractional bushel values\nnew_pumpkins <- new_pumpkins %>% \n  mutate(price = case_when(\n    str_detect(package, \"1 1/9\") ~ price/(1.1),\n    str_detect(package, \"1/2\") ~ price*2,\n    TRUE ~ price))\n\n# View the first few rows of the data\nnew_pumpkins %>% \n  slice_head(n = 30)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 30 × 9\n   variety  city_name package  low_price high_price date         day month price\n   <chr>    <chr>     <chr>        <dbl>      <dbl> <date>     <dbl> <dbl> <dbl>\n 1 PIE TYPE BALTIMORE 1 1/9 b…        15       15   2016-09-24   268     9  13.6\n 2 PIE TYPE BALTIMORE 1 1/9 b…        18       18   2016-09-24   268     9  16.4\n 3 PIE TYPE BALTIMORE 1 1/9 b…        18       18   2016-10-01   275    10  16.4\n 4 PIE TYPE BALTIMORE 1 1/9 b…        17       17   2016-10-01   275    10  15.5\n 5 PIE TYPE BALTIMORE 1 1/9 b…        15       15   2016-10-08   282    10  13.6\n 6 PIE TYPE BALTIMORE 1 1/9 b…        18       18   2016-10-08   282    10  16.4\n 7 PIE TYPE BALTIMORE 1 1/9 b…        17       17   2016-10-08   282    10  15.5\n 8 PIE TYPE BALTIMORE 1 1/9 b…        17       18.5 2016-10-08   282    10  16.1\n 9 PIE TYPE BALTIMORE 1 1/9 b…        15       15   2016-10-15   289    10  13.6\n10 PIE TYPE BALTIMORE 1 1/9 b…        17       17   2016-10-15   289    10  15.5\n# ℹ 20 more rows\n```\n:::\n:::\n\n\n## Data Visualization\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set theme\ntheme_set(theme_light())\n\n# Make a scatter plot of day and price\nnew_pumpkins %>% \n  ggplot(mapping = aes(x = day, y = price)) +\n  geom_point(size = 1.6) +\n  ggtitle(\"Pumpkin Sales Throughout the Year\")\n```\n\n::: {.cell-output-display}\n![](Lab1-ML_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n*Question 3:* Is this a useful plot? Does anything about it surprise you?\n\nThis is not a useful plot. It's clearly evident that prices range broadly throughout the year after selecting for bushels, a better way to visualize this data for our viewers is to find the mean price for each month.\n\nHow do we make it more useful? To get charts to display useful data, you usually need to group the data somehow.\n\n*Question 4:* Group the pumpkins into groups based on the month column and then find the mean price for each month. Plot the results with a bar plot.\n\nHint: use dplyr::group_by() %\\>% summarize()\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Find the average price of pumpkins per month then plot a bar chart\npumpkins %>%\n  group_by(month) %>% \n  summarise(mean_price = mean(price)) %>% \n  ggplot(aes(x = month, y = mean_price)) +\n  geom_col(fill = \"midnightblue\", alpha = 0.7) +\n  ylab(\"Pumpkin Price\") +\n  ggtitle(\"Mean Pumpkin Price for Each Month\")\n```\n\n::: {.cell-output-display}\n![](Lab1-ML_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n#Preprocessing data for modelling using recipes\n\nWhat if we wanted to predict the price of a pumpkin based on the city or package columns which are of type character? How could we find the correlation between, say, package and price?\n\nMachine learning models work best with numeric features rather than text values, so you generally need to convert categorical features into numeric representations.\n\nThis means that we have to find a way to reformat our predictors to make them easier for a model to use effectively, a process known as **feature engineering**.\n\nDifferent models have different preprocessing requirements. For instance, least squares requires encoding categorical variables such as month, variety and city_name. This simply involves translating a column with categorical values into one or more numeric columns that take the place of the original.\n\nNow let's introduce another useful tidymodels package: recipes - which will help you preprocess data before training your mode. A recipe is an object that defines what steps should be applied to a data set in order to get it ready for modelling.\n\nNow, let's create a recipe that prepares our data for modelling by substituting a unique integer for all the observations in the predictor columns:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Specify a recipe\npumpkins_recipe <- recipe(price ~ ., data = new_pumpkins) %>%  #the dot means adding all x variables together to yield price \n  step_integer(all_predictors(), zero_based = TRUE) #new data creates a specific recipe coverting new data into set of integers\n\n\n# Print out the recipe\npumpkins_recipe\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Recipe ──────────────────────────────────────────────────────────────────────\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Inputs \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nNumber of variables by role\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\noutcome:   1\npredictor: 8\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Operations \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n• Integer encoding for: all_predictors()\n```\n:::\n:::\n\n\nOK, we created our first recipe that specifies an outcome (price) and its corresponding predictors and that all the predictor columns should be encoded into a set of integers. Let's quickly break it down:\n\nThe call to recipe() with a formula tells the recipe the roles of the variables using new_pumpkins data as the reference. For instance the price column has been assigned an outcome role while the rest of the columns have been assigned a predictor role.\n\nstep_integer(all_predictors(), zero_based = TRUE) specifies that all the predictors should be converted into a set of integers with the numbering starting at 0.\n\nHow can we confirm that the recipe is doing what we intend? Once your recipe is defined, you can estimate the parameters required to preprocess the data, and then extract the processed data. You don't typically need to do this when you use tidymodels (we'll see the normal convention in just a minute with workflows) but its a good sanity check for confirming that recipes are doing what you expect.\n\nFor that, you'll need two more verbs: prep() and bake()\n\nprep(): estimates the required parameters from a training set that can be later applied to other data sets.\n\nbake(): takes a prepped recipe and applies the operations to any data set.\n\nNow let's prep and bake our recipes to confirm that under the hood, the predictor columns will be first encoded before a model is fit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prep the recipe\npumpkins_prep <- prep(pumpkins_recipe)\n\n# Bake the recipe to extract a preprocessed new_pumpkins data\nbaked_pumpkins <- bake(pumpkins_prep, new_data = NULL)\n\n# Print out the baked data set\nbaked_pumpkins %>% \n  slice_head(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 9\n   variety city_name package low_price high_price  date   day month price\n     <int>     <int>   <int>     <int>      <int> <int> <int> <int> <dbl>\n 1       3         1       0         5          3     0     5     1  13.6\n 2       3         1       0        10          7     0     5     1  16.4\n 3       3         1       0        10          7     6    11     2  16.4\n 4       3         1       0         9          6     6    11     2  15.5\n 5       3         1       0         5          3     7    12     2  13.6\n 6       3         1       0        10          7     7    12     2  16.4\n 7       3         1       0         9          6     7    12     2  15.5\n 8       3         1       0         9          8     7    12     2  16.1\n 9       3         1       0         5          3     8    13     2  13.6\n10       3         1       0         9          6     8    13     2  15.5\n```\n:::\n:::\n\n\nThe processed data baked_pumpkins has all its predictors encoded confirming that indeed the preprocessing steps defined as our recipe will work as expected. This makes it harder for you to read but more intelligible for tidymodels. Take a look at how the observations have been mapped to numbers.\n\n*Question 5:* From looking at the baked_pumpkins tibble, how many total cities are represented in the data set?\n\nThere are 10 cities represented in this data set.\n\nbaked_pumpkins is a data frame that we can perform computations on. For instance, let's try to find a good correlation between two variables to potentially build a good predictive model. We'll use the function cor() to do this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Find the correlation between the package and the price\ncor(baked_pumpkins$package, baked_pumpkins$price)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6061713\n```\n:::\n:::\n\n\n*Question 6:* Calculate the correlation between pumpkin price and two other variables in the data set\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Correlation between price and other vars.\ncor(baked_pumpkins$city_name, baked_pumpkins$price) #0.324\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3236397\n```\n:::\n\n```{.r .cell-code}\ncor(baked_pumpkins$variety, baked_pumpkins$price) #-0.863\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.863479\n```\n:::\n\n```{.r .cell-code}\ncor(baked_pumpkins$month, baked_pumpkins$price) #-0.149\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.1487829\n```\n:::\n:::\n\n\n*Question 7:* Which of these three variables is most highly correlated with price? Why might this be?\n\nOut of the three variables, city_name is most highly correlated with price at -0.86. It appears that pumpkin price varies by city.\n\nNow let's visualize a correlation matrix of all the columns using the corrplot package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the corrplot package\nlibrary(corrplot)\n\n# Obtain correlation matrix\ncorr_mat <- cor(baked_pumpkins %>% \n                  # Drop columns that are not really informative\n                  select(-c(low_price, high_price)))\n\n# Make a correlation plot between the variables\ncorrplot(corr_mat, method = \"shade\", shade.col = NA, tl.col = \"black\", tl.srt = 45, addCoef.col = \"black\", cl.pos = \"n\", order = \"original\")\n```\n\n::: {.cell-output-display}\n![](Lab1-ML_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n## Build a linear regression model\n\nNow that we have build a recipe, and actually confirmed that the data will be pre-processed appropriately, let's now build a regression model to answer the question: What price can I expect of a given pumpkin package?\n\n## Train the model using the training set\n\nAs you may have already figured out, the column price is the outcome variable while the package column is the predictor variable.\n\nTo do this, we'll first split the data. Data splitting is a key part of the machine learning process. For now we'll do a 80/20 split, where 80% of the data goes into training and 20% into the test set. Then we'll define a recipe that will encode the predictor column into a set of integers, then build a model specification. We won't prep and bake our recipe since we already know it will preprocess the data as expected.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#random number generator\nset.seed(123)\n# Split the data into training and test sets\npumpkins_split <- baked_pumpkins %>%  #new_pumpkins should be baked_pumpkins \n  initial_split(prop = 0.8)\n\n\n# Extract training and test data\npumpkins_train <- training(pumpkins_split)\npumpkins_test <- testing(pumpkins_split)\n\n\n# Create a recipe for preprocessing the data\nlm_pumpkins_recipe <- recipe(price ~ package, data = pumpkins_train) %>% \n  step_integer(all_predictors(), zero_based = TRUE)\n\n\n# Create a linear model specification\nlm_spec <- linear_reg() %>% \n  set_engine(\"lm\") %>% \n  set_mode(\"regression\")\n```\n:::\n\n\nNow that we have a recipe and a model specification, we need to find a way of bundling them together into an object that will first preprocess the data (prep+bake behind the scenes), fit the model on the preprocessed data and also allow for potential post-processing activities.\n\nSo let's bundle everything up into a workflow. A workflow is a container object that aggregates information required to fit and predict from a model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Hold modeling components in a workflow\nlm_wf <- workflow() %>% \n  add_recipe(lm_pumpkins_recipe) %>% \n  add_model(lm_spec)\n\n# Print out the workflow\nlm_wf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_integer()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n```\n:::\n:::\n\n\nA workflow can be fit/trained in much the same way a model can.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Train the model\nlm_wf_fit <- lm_wf %>% \n  fit(data = pumpkins_train)\n\n# Print the model coefficients learned \nlm_wf_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_integer()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n(Intercept)      package  \n      20.14         4.76  \n```\n:::\n:::\n\n\nFrom the model output, we can see the coefficients learned during training. They represent the coefficients of the line of best fit that gives us the lowest overall error between the actual and predicted variable.\n\nEvaluate model performance using the test set. It's time to see how the model performed! How do we do this?\n\nNow that we've trained the model, we can use it to make predictions for the test_set using parsnip::predict(). Then we can compare these predictions to the actual label values to evaluate how well (or not!) the model is working. - training model: data youre using to test if the model works - testing model: actually employing the model\n\nLet's start with making predictions for the test set then bind the columns to the test set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Make predictions for the test set\npredictions <- lm_wf_fit %>% \n  predict(new_data = pumpkins_test)\n\n# Bind predictions to the test set\nlm_results <- pumpkins_test %>% \n  select(c(package, price)) %>% \n  bind_cols(predictions)\n\n\n# Print the first ten rows of the tibble\nlm_results %>% \n  slice_head(n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 3\n   package price .pred\n     <int> <dbl> <dbl>\n 1       0  13.6  20.1\n 2       0  16.4  20.1\n 3       0  16.4  20.1\n 4       0  13.6  20.1\n 5       0  15.5  20.1\n 6       0  16.4  20.1\n 7       2  34    29.7\n 8       2  30    29.7\n 9       2  30    29.7\n10       2  34    29.7\n```\n:::\n:::\n\n\nOK, you have just trained a model and used it to make predictions! Let's evaluate the model's performance.\n\nIn tidymodels, we do this using yardstick::metrics(). For linear regression, let's focus on the following metrics:\n\nRoot Mean Square Error (RMSE): The square root of the MSE. This yields an absolute metric in the same unit as the label (in this case, the price of a pumpkin). The smaller the value, the better the model (in a simplistic sense, it represents the average price by which the predictions are wrong)\n\nCoefficient of Determination (usually known as R-squared or R2): A relative metric in which the higher the value, the better the fit of the model. In essence, this metric represents how much of the variance between predicted and actual label values the model is able to explain.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Evaluate performance of linear regression\nmetrics(data = lm_results,\n        truth = price,\n        estimate = .pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       7.23 \n2 rsq     standard       0.495\n3 mae     standard       5.94 \n```\n:::\n:::\n\n\nOK, so that is the model performance. Let's see if we can get a better indication by visualizing a scatter plot of the package and price then use the predictions made to overlay a line of best fit.\n\nThis means we'll have to prep and bake the test set in order to encode the package column then bind this to the predictions made by our model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Encode package column\npackage_encode <- lm_pumpkins_recipe %>% \n  prep() %>% \n  bake(new_data = pumpkins_test) %>% \n  select(package)\n\n\n# Bind encoded package column to the results\n plot_results <- lm_results %>%\n bind_cols(package_encode %>%\n               rename(package_integer = package)) %>%\n  relocate(package_integer, .after = package)\n\n# Print new results data frame\nplot_results %>%\n  slice_head(n = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 4\n  package package_integer price .pred\n    <int>           <int> <dbl> <dbl>\n1       0               0  13.6  20.1\n2       0               0  16.4  20.1\n3       0               0  16.4  20.1\n4       0               0  13.6  20.1\n5       0               0  15.5  20.1\n```\n:::\n\n```{.r .cell-code}\n# Make a scatter plot\nplot_results %>%\n  ggplot(mapping = aes(x = package_integer, y = price)) +\n   geom_point(size = 1.6) +\n   # Overlay a line of best fit\n   geom_line(aes(y = .pred), color = \"orange\", linewidth = 1.2) +\n   xlab(\"package\") +\n  ggtitle(\"Pumpkin Sales Throughout the Year\") \n```\n\n::: {.cell-output-display}\n![](Lab1-ML_files/figure-html/encode_package-1.png){width=672}\n:::\n:::\n\n\nHmm. The model does not do good job of generalizing the relationship between a package and its corresponding price.\n\n*Question 8:* What issues do you see with fitting a linear regression to this data?\n\nFitting this data with a linear regression does not produce a line of best fit and the data is clearly not a linear relationship. It can also be concluded that the residual sum of squared errors are quite big. Finally, the line seems to only go through about two points.\n\nCongratulations, you just created a model that can help predict the price of a few varieties of pumpkins. But you can probably create a better model! To be continued next week...",
    "supporting": [
      "Lab1-ML_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}